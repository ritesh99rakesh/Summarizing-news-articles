# Summarizing-news-articles
Every day, people rely on a wide variety of sources to stay informed, from news stories to social media posts to search results. Being able to develop Machine Learning models that can automatically deliver accurate summaries of longer text can be useful for digesting such large amounts of information in a compressed form, and is a long-term goal of our team.

Summarization can also serve as an interesting reading comprehension test for machines. To summarize well, machine learning models need to be able to comprehend documents and distill the important information, tasks which are highly challenging for computers, especially as the length of a document increases.

As the project name suggests our aim is to teach computer enough so that it can give summary of the lengthy news articles or as a matter of fact any articles (given proper data set to train and required processing units).
So basically we are using various concepts of machine learning and deep learning to train our model for generating summary of a given article.
In our case we have used ‘reuters’ corpus from NLTK as training dataset and tensorflow module for training the model.
